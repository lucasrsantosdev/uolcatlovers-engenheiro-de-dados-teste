
## â„¹ï¸â„¹ï¸â„¹ï¸â€œCopie example.env para .env antes de rodar.â€â„¹ï¸â„¹ï¸â„¹ï¸ ##

## ğŸ§­ VisÃ£o Geral

ğŸ“Œ Projeto desenvolvido para o case da Uol, simulando a evoluÃ§Ã£o de uma startup desde uma extraÃ§Ã£o simples de dados atÃ© uma arquitetura analÃ­tica escalÃ¡vel em nuvem.

âš ï¸ Durante o desenvolvimento, a API pÃºblica utilizada apresentou indisponibilidade constante (HTTP 503). Em vez de contornar ou ignorar esse cenÃ¡rio, a soluÃ§Ã£o foi pensada para lidar com falhas reais de integraÃ§Ã£o, mantendo contratos de dados estÃ¡veis e permitindo a evoluÃ§Ã£o futura da arquitetura.
A indisponibilidade da API nÃ£o foi tratada como um bloqueio, mas como parte do problema a ser resolvido

ğŸ§  Essa abordagem reflete um cenÃ¡rio comum em ambientes de produÃ§Ã£o, onde dependÃªncias externas nem sempre estÃ£o disponÃ­veis.

â„¹ï¸  Obs: As configuraÃ§Ãµes de ambiente (URL da API, timeouts, paths e parÃ¢metros de execuÃ§Ã£o)
foram isoladas em variÃ¡veis de ambiente (`.env`), seguindo boas prÃ¡ticas de seguranÃ§a
e permitindo fÃ¡cil adaptaÃ§Ã£o entre ambientes local, cloud e CI/CD.


## ğŸ QuestÃ£o 1 â€“ ExtraÃ§Ã£o de Cat Facts (Python)

ğŸ Foi desenvolvido um script simples em Python para extrair fatos sobre gatos a partir da API pÃºblica Cat Facts, seguindo a documentaÃ§Ã£o oficial do projeto.

ğŸš¨ Durante os testes, a API apresentou instabilidade contÃ­nua. Todos os endpoints testados (/facts e /facts/random) retornaram erro HTTP 503 (Service Unavailable), indicando que o backend da aplicaÃ§Ã£o (Heroku free dyno) estÃ¡ fora do ar ou descontinuado.

ğŸ› ï¸ Mesmo com essa limitaÃ§Ã£o externa, optei por manter o script como se estivesse lidando com um cenÃ¡rio real de produÃ§Ã£o:

ğŸ›¡ï¸ Lidar de forma resiliente com falhas de API

ğŸ” Realizar mÃºltiplas tentativas de coleta

ğŸ“„ Manter o contrato de saÃ­da dos dados

ğŸ’¾ Gerar o arquivo CSV local com cabeÃ§alho, mesmo quando nÃ£o hÃ¡ registros

âœ… Com isso, o pipeline permanece estÃ¡vel e previsÃ­vel, algo essencial em integraÃ§Ãµes com serviÃ§os externos que podem ficar indisponÃ­veis temporariamente.

## â˜ï¸ QuestÃ£o 2 â€“ Arquitetura em Nuvem (Google Cloud)

â˜ï¸ Abaixo estÃ¡ uma proposta simples de arquitetura em Google Cloud para substituir a soluÃ§Ã£o local, permitindo extrair, armazenar e disponibilizar os dados de forma escalÃ¡vel para o usuÃ¡rio final.

ğŸ—ï¸ Essa arquitetura foi pensada para crescer junto com o volume de dados e, se necessÃ¡rio, pode ser implementada sem grandes mudanÃ§as estruturais.

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cat Facts API (External) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ HTTPS
              v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cloud Run â€“ Extract Service     â”‚
â”‚ - Consume /facts/random         â”‚
â”‚ - Payload validation            â”‚
â”‚ - Logging & error handling      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ Events
              v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pub/Sub                        â”‚
â”‚ Topic: cat-facts-raw            â”‚
â”‚ - Decoupling                   â”‚
â”‚ - Automatic retries            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Processing (Dataflow / Run)    â”‚
â”‚ - Normalization                â”‚
â”‚ - Deduplication (_id)          â”‚
â”‚ - Enrichment                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚ RAW     â”‚ CURATED
              v         v
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cloud Storage     â”‚   â”‚ BigQuery            â”‚
â”‚ bucket/raw        â”‚   â”‚ dataset.cat_facts  â”‚
â”‚ jsonl / csv       â”‚   â”‚ analytic table     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                        â”‚
           v                        v
 Reprocessing / Audit        Looker / SQL / Apps

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Cloud Scheduler           â”‚
â”‚ - Triggers ingestion      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



## ğŸ§  ConsideraÃ§Ãµes de Arquitetura

âš™ï¸ Cloud Run foi escolhido por ser serverless, simples de operar e escalar automaticamente conforme a demanda.

ğŸ“¬ Pub/Sub desacopla a ingestÃ£o do processamento, evitando perda de dados em cenÃ¡rios de falha ou picos de volume.

ğŸ§± Cloud Storage (RAW) mantÃ©m os dados originais, permitindo auditoria e reprocessamento quando necessÃ¡rio.

ğŸ“Š BigQuery funciona como a camada analÃ­tica final, facilitando o consumo pelo time de analytics.

ğŸš€ Essa arquitetura permite evoluir facilmente para um modelo near real-time no futuro, sem mudanÃ§as estruturais grandes.

â„¹ï¸ Obs: para um volume pequeno, Cloud Functions tambÃ©m seria viÃ¡vel. A escolha do Cloud Run foi feita pensando em evoluÃ§Ã£o de carga, controle de dependÃªncias e facilidade de versionamento do serviÃ§o.

## ğŸ§¾ QuestÃ£o 3 â€“ Esquema da Tabela (BigQuery)

ğŸ§¾ Esse esquema foi modelado para suportar consultas analÃ­ticas, auditoria e possÃ­veis evoluÃ§Ãµes futuras do pipeline.

ğŸ“‚ sql no caminho abaixo

sql/bigquery/01_create_table_cat_facts.sql

## ğŸ“Š QuestÃ£o 4 â€“ Consulta de Fatos Atualizados (BigQuery)

ğŸ“Š Para apoiar o time de analytics, foi criada uma consulta SQL que extrai todos os fatos sobre gatos que foram atualizados durante o mÃªs de agosto de 2020.
â±ï¸ A consulta utiliza o campo updated_at como TIMESTAMP e trabalha com intervalo fechado/aberto para garantir precisÃ£o temporal.

ğŸ“‚ O SQL ta no caminho abaixo

sql/bigquery/02_select_cat_facts_updated_aug_2020.sql

## ğŸ² QuestÃ£o 5 â€“ Amostra AleatÃ³ria para QA (BigQuery)

ğŸ² Para atender o time de desenvolvimento, foi criada uma consulta SQL que extrai uma amostra aleatÃ³ria de 100 registros da base de fatos sobre gatos.

ğŸ§ª A consulta retorna apenas os campos necessÃ¡rios para o ambiente de QA:

ğŸ“Texto do fato

ğŸ“…Data de criaÃ§Ã£o

â±ï¸Data de atualizaÃ§Ã£o

ğŸ“¤O resultado pode ser exportado diretamente para um arquivo CSV separado por vÃ­rgulas utilizando as funcionalidades nativas do BigQuery.

ğŸ“‚sql no caminho abaixo

sql/bigquery/03_sample_cat_facts_for_qa.sql

## ğŸ”® PrÃ³ximos Passos PossÃ­veis

ğŸ§¬ Implementar controle de versionamento de schema

ğŸ§ª Criar testes automatizados para o extrator

ğŸ“¡ Adicionar monitoramento e alertas (Cloud Monitoring)

ğŸ” Implementar carga incremental baseada em updated_at